{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pytorch modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.optim import lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defines the generator that consists of Resnet blocks between a few\n",
    "# downsampling/upsampling operations.\n",
    "# Code and idea originally from Justin Johnson's architecture.\n",
    "# https://github.com/jcjohnson/fast-neural-style/\n",
    "class Resnet_Encoder(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc=512, ngf=32, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, gpu_ids=[], padding_type='reflect'):\n",
    "        assert(n_blocks >= 0)\n",
    "        super(Resnet_Encoder, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = ngf\n",
    "        self.gpu_ids = gpu_ids\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(3),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0,\n",
    "                           bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "\n",
    "        n_downsampling = 4\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3,\n",
    "                                stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "\n",
    "        mult = 2**n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
    "\n",
    "#         for i in range(n_downsampling):\n",
    "#             mult = 2**(n_downsampling - i)\n",
    "#             model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),\n",
    "#                                          kernel_size=3, stride=2,\n",
    "#                                          padding=1, output_padding=1,\n",
    "#                                          bias=use_bias),\n",
    "#                       norm_layer(int(ngf * mult / 2)),\n",
    "#                       nn.ReLU(True)]\n",
    "#         model += [nn.ReflectionPad2d(3)]\n",
    "#         model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
    "#         model += [nn.Tanh()]\n",
    "        \n",
    "        for i in range(n_downsampling-1):\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult, kernel_size=3,\n",
    "                                stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult),\n",
    "                      nn.ReLU(True)]\n",
    "        model += [nn.Conv2d(ngf * mult, ngf * mult, kernel_size=3,\n",
    "                                stride=2, padding=1, bias=use_bias)]\n",
    "    \n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.gpu_ids and isinstance(input.data, torch.cuda.FloatTensor):\n",
    "            return nn.parallel.data_parallel(self.model, input, self.gpu_ids)\n",
    "        else:\n",
    "            return self.model(input)\n",
    "        \n",
    "\n",
    "\n",
    "# Define a resnet block\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
    "                       norm_layer(dim),\n",
    "                       nn.ReLU(True)]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
    "                       norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ThreeD_Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ThreeD_Decoder, self).__init__()\n",
    "#         self.args = args\n",
    "#         self.cube_len = args.cube_len\n",
    "        \n",
    "        # hyperparameters\n",
    "        self.z_size = 512\n",
    "        self.cube_len = 64\n",
    "        self.bias = True\n",
    "\n",
    "        padd = (0, 0, 0)\n",
    "#         if self.cube_len == 32:\n",
    "#             padd = (1,1,1)\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.z_size, self.cube_len*4, kernel_size=4, stride=2, bias=self.bias, padding=padd),\n",
    "            torch.nn.BatchNorm3d(self.cube_len*4),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_len*4, self.cube_len*2, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.BatchNorm3d(self.cube_len*2),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_len*2, self.cube_len*1, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.BatchNorm3d(self.cube_len*1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_len*1, self.cube_len//2, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.BatchNorm3d(self.cube_len//2),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_len//2, 1, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.view(-1, self.z_size, 1, 1, 1)\n",
    "        #print(out.size())  # torch.Size([100, 512, 1, 1, 1])\n",
    "        out = self.layer1(out)\n",
    "        #print(out.size())  # torch.Size([100, 512, 4, 4, 4])\n",
    "        out = self.layer2(out)\n",
    "        #print(out.size())  # torch.Size([100, 256, 8, 8, 8])\n",
    "        out = self.layer3(out)\n",
    "        #print(out.size())  # torch.Size([100, 128, 16, 16, 16])\n",
    "        out = self.layer4(out)\n",
    "        #print(out.size())  # torch.Size([100, 64, 32, 32, 32])\n",
    "        out = self.layer5(out)\n",
    "        #print(out.size())  # torch.Size([100, 1, 64, 64, 64])\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import test data\n",
    "img = imageio.imread('val_imgs/000031/001.png')\n",
    "img = np.asarray(img)\n",
    "img_tensor = torch.from_numpy(img).view(1, *img.shape).narrow(-1,0,3).type(torch.FloatTensor).permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate models\n",
    "Encoder1 = Resnet_Encoder(3)\n",
    "Decoder1 = ThreeD_Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test forward pass\n",
    "code = Encoder1(img_tensor).view(1,-1,1,1,1)\n",
    "output = Decoder1(code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
