{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "import itertools\n",
    "# import util.util as util\n",
    "# from util.image_pool import ImagePool\n",
    "# from .base_model import BaseModel\n",
    "# from . import networks\n",
    "# import pytorch modules\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import functools\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find gpu\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "class Options():\n",
    "    def __init__(self):\n",
    "        self.isTrain = True\n",
    "        self.checkpoints_dir = 'checkpoints'\n",
    "        self.beta1 = 0.5\n",
    "        self.pool_size = 50\n",
    "        self.lambda_A = 10.\n",
    "        self.lambda_B = 10.\n",
    "        self.lambda_identity = 0\n",
    "        \n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "class BaseModel():\n",
    "    def name(self):\n",
    "        return 'BaseModel'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "        self.save_dir = opt.checkpoints_dir\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    # used in test time, no backprop\n",
    "    def test(self):\n",
    "        pass\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        pass\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        return self.input\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        return {}\n",
    "\n",
    "    def save(self, label):\n",
    "        pass\n",
    "\n",
    "    # helper saving function that can be used by subclasses\n",
    "    def save_network(self, network, network_label, epoch_label, gpu_ids):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        torch.save(network.state_dict(), save_path)\n",
    "\n",
    "    # helper loading function that can be used by subclasses\n",
    "    def load_network(self, network, network_label, epoch_label):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        network.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    # update learning rate (called once every epoch)\n",
    "    def update_learning_rate(self):\n",
    "        for scheduler in self.schedulers:\n",
    "            scheduler.step()\n",
    "        lr = self.optimizers[0].param_groups[0]['lr']\n",
    "        print('learning rate = %.7f' % lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2im(image_tensor, imtype=np.uint8):\n",
    "    image_numpy = image_tensor[0].cpu().float().numpy()\n",
    "    if image_numpy.shape[0] == 1:\n",
    "        image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
    "    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "    return image_numpy.astype(imtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, target_real_label=1.0, target_fake_label=0.0,\n",
    "                 tensor=torch.FloatTensor):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.real_label = target_real_label\n",
    "        self.fake_label = target_fake_label\n",
    "        self.Tensor = tensor\n",
    "        self.loss = nn.BCELoss()\n",
    "#         if use_lsgan:\n",
    "#             self.loss = nn.MSELoss()\n",
    "#         else:\n",
    "#             self.loss = nn.BCELoss()\n",
    "\n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        target_tensor = None\n",
    "        if target_is_real:\n",
    "            real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n",
    "            self.real_label_var = Variable(real_tensor, requires_grad=False)\n",
    "            target_tensor = self.real_label_var\n",
    "        else:\n",
    "            fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
    "            self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
    "            target_tensor = self.fake_label_var\n",
    "        return target_tensor\n",
    "\n",
    "    def __call__(self, input, target_is_real):\n",
    "        target_tensor = self.get_target_tensor(input, target_is_real)\n",
    "        return self.loss(input, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return Variable(images)\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = np.random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = np.random.randint(0, self.pool_size - 1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = Variable(torch.cat(return_images, 0))\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder3d, self).__init__()\n",
    "        \n",
    "        # hyperparameters\n",
    "        self.z_size = 200\n",
    "        self.cube_len = 32\n",
    "        self.bias = True\n",
    "\n",
    "        padd = (0, 0, 0)\n",
    "\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.z_size, self.cube_len*4, kernel_size=4, stride=2,\\\n",
    "                                     bias=self.bias, padding=padd),\n",
    "            torch.nn.BatchNorm3d(self.cube_len*4),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_len*4, self.cube_len*2, kernel_size=4, stride=2, bias=self.bias,\\\n",
    "                                     padding=(1, 1, 1)),\n",
    "            torch.nn.BatchNorm3d(self.cube_len*2),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_len*2, self.cube_len*1, kernel_size=4, stride=2, bias=self.bias,\\\n",
    "                                     padding=(1, 1, 1)),\n",
    "            torch.nn.BatchNorm3d(self.cube_len*1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose3d(self.cube_len, 1, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.unsqueeze(-1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "#         print(out.size())\n",
    "        out = self.layer3(out)\n",
    "#         print(out.size())\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder3d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder3d, self).__init__()\n",
    "        \n",
    "        # hyperparameters\n",
    "        self.z_size = 200\n",
    "        self.cube_len = 32\n",
    "        self.bias = True\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.cube_len, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(self.cube_len*1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv3d(self.cube_len, self.cube_len*2, kernel_size=4, stride=2, bias=self.bias,\\\n",
    "                                     padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(self.cube_len*2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv3d(self.cube_len*2, self.cube_len*4, kernel_size=4, stride=2, bias=self.bias,\\\n",
    "                                     padding=(1, 1, 1)),\n",
    "            nn.BatchNorm3d(self.cube_len*4),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv3d(self.cube_len*4, self.z_size, kernel_size=4, stride=2,\\\n",
    "                                     bias=self.bias, padding=(0,0,0)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder2d(nn.Module):\n",
    "    def __init__(self, input_nc=200, output_nc=1, ngf=8, norm_layer=nn.BatchNorm2d,\\\n",
    "                 use_dropout=False, padding_type='reflect'):\n",
    "        super(Decoder2d, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = ngf\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "       \n",
    "\n",
    "        model = []\n",
    "        \n",
    "        n_upsampling = 4\n",
    "        mult = 2**(n_upsampling-1)\n",
    "        \n",
    "        model += [nn.ConvTranspose2d(input_nc, ngf * mult * 2, kernel_size=2,\n",
    "                                    stride=1, padding=0, bias=use_bias),\\\n",
    "                                norm_layer(ngf * mult * 2),\n",
    "                                nn.ReLU(True)]\n",
    "        \n",
    "        \n",
    "        for i in range(2):\n",
    "            model += [nn.ConvTranspose2d(ngf * mult * 2, ngf * mult * 2, kernel_size=3,\n",
    "                                        stride=2, padding=1, bias=use_bias),\n",
    "                              norm_layer(ngf * mult * 2),\n",
    "                              nn.ReLU(True)]\n",
    "            \n",
    "        # padding to maintain output size\n",
    "        p2d = (1, 1, 1, 1) \n",
    "        model += [nn.ZeroPad2d(p2d),]\n",
    "        \n",
    "        for i in range(n_upsampling):\n",
    "            mult = 2**(n_upsampling-1-i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult * 2, ngf * mult, kernel_size=5,\n",
    "                                stride=2, padding=1, bias=use_bias),\\\n",
    "                      norm_layer(ngf * mult),\n",
    "                      nn.ReLU(True)]\n",
    "        \n",
    "        # padding to maintain output size\n",
    "        p2d = (0, 1, 0, 1) \n",
    "        model += [nn.ZeroPad2d(p2d),]\n",
    "        \n",
    "        model += [#nn.ReflectionPad2d(2),\n",
    "                 nn.ConvTranspose2d(ngf, output_nc, kernel_size=5, padding=2,\n",
    "                           bias=use_bias)]\n",
    "        \n",
    "#         self.model = nn.Sequential(*model)\n",
    "        self.model = nn.ModuleList(model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.squeeze(-1)\n",
    "        for model in self.model:\n",
    "            out = model(out)\n",
    "#             print(out.size())\n",
    "#         out = self.model(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder2d(nn.Module):\n",
    "    def __init__(self, input_nc=1, output_nc=200, ngf=8, norm_layer=nn.BatchNorm2d,\\\n",
    "                 use_dropout=False, padding_type='reflect'):\n",
    "        super(Encoder2d, self).__init__()\n",
    "        self.input_nc = input_nc\n",
    "        self.output_nc = output_nc\n",
    "        self.ngf = ngf\n",
    "        if type(norm_layer) == functools.partial:\n",
    "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "\n",
    "        model = [nn.ReflectionPad2d(2),\n",
    "                 nn.Conv2d(input_nc, ngf, kernel_size=5, padding=0,\n",
    "                           bias=use_bias),\n",
    "                 norm_layer(ngf),\n",
    "                 nn.ReLU(True)]\n",
    "        \n",
    "        \n",
    "        n_downsampling = 4\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=5,\n",
    "                                stride=2, padding=1, bias=use_bias),\n",
    "                      norm_layer(ngf * mult * 2),\n",
    "                      nn.ReLU(True)]\n",
    "        \n",
    "        for i in range(2):\n",
    "            model += [nn.Conv2d(ngf * mult * 2, ngf * mult * 2, kernel_size=3,\n",
    "                                    stride=2, padding=1, bias=use_bias),\n",
    "                          norm_layer(ngf * mult * 2),\n",
    "                          nn.ReLU(True)]\n",
    "            \n",
    "        model += [nn.Conv2d(ngf * mult * 2, output_nc, kernel_size=2,\n",
    "                                    stride=1, padding=0, bias=use_bias)]\n",
    "        model += [nn.Tanh()]\n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "#         mult = 2**(n_downsampling-1)\n",
    "#         for i in range(n_blocks):\n",
    "#             model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer,\\\n",
    "#                                   use_dropout=use_dropout, use_bias=use_bias)]\n",
    "            \n",
    "        self.model = nn.ModuleList(model)\n",
    "#         self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for model in self.model:\n",
    "            x = model(x)\n",
    "#             print(x.size())\n",
    "        return x\n",
    "        #return self.model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv3d: (in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "# input size (N,Cin,D,H,W) and output (N,Cout,Dout,Hout,Wout) \n",
    "\n",
    "\n",
    "class Discriminator3d(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator3d, self).__init__()\n",
    "        self.cube_len = 32\n",
    "        self.leak_value = 0.2\n",
    "        self.bias = False\n",
    "\n",
    "        padd = (0,0,0)\n",
    "        if self.cube_len == 32:\n",
    "            padd = (1,1,1)\n",
    "            \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(1, self.cube_len, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.BatchNorm3d(self.cube_len),\n",
    "            torch.nn.LeakyReLU(self.leak_value)\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(self.cube_len, self.cube_len*2, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.BatchNorm3d(self.cube_len*2),\n",
    "            torch.nn.LeakyReLU(self.leak_value)\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(self.cube_len*2, self.cube_len*4, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.BatchNorm3d(self.cube_len*4),\n",
    "            torch.nn.LeakyReLU(self.leak_value)\n",
    "        )\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(self.cube_len*4, self.cube_len*8, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1, 1)),\n",
    "            torch.nn.BatchNorm3d(self.cube_len*8),\n",
    "            torch.nn.LeakyReLU(self.leak_value)\n",
    "        )\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv3d(self.cube_len*8, 1, kernel_size=4, stride=2, bias=self.bias, padding=padd),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        out = x.view(-1, 1, self.cube_len, self.cube_len, self.cube_len)\n",
    "#         print(out.size()) # torch.Size([100, 1, 32, 32, 32])\n",
    "        out = self.layer1(out)\n",
    "#         print(out.size())  # torch.Size([100, 32, 16, 16, 16])\n",
    "        out = self.layer2(out)\n",
    "#         print(out.size())  # torch.Size([100, 64, 8, 8, 8])\n",
    "        out = self.layer3(out)\n",
    "#         print(out.size())  # torch.Size([100, 128, 4, 4, 4])\n",
    "        out = self.layer4(out)\n",
    "#         print(out.size())  # torch.Size([100, 256, 2, 2, 2])\n",
    "        out = self.layer5(out)\n",
    "#         print(out.size())  # torch.Size([100, 1, 1, 1, 1])\n",
    "\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Images are 128*128 into batch * 1\n",
    "class Discriminator2d(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator2d, self).__init__()\n",
    "        self.image_len = 128\n",
    "        self.leak_value = 0.2\n",
    "        self.bias = False\n",
    "\n",
    "        padd = (0,0,0)\n",
    "        if self.image_len == 128:\n",
    "            padd = (1,1)\n",
    "            \n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, self.image_len, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1)),\n",
    "            torch.nn.BatchNorm2d(self.image_len),\n",
    "            torch.nn.LeakyReLU(self.leak_value)\n",
    "        )\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.image_len, self.image_len*2, kernel_size=4, stride=4, bias=self.bias, padding=(1, 1)),\n",
    "            torch.nn.BatchNorm2d(self.image_len*2),\n",
    "            torch.nn.LeakyReLU(self.leak_value)\n",
    "        )\n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.image_len*2, self.image_len*4, kernel_size=4, stride=4, bias=self.bias, padding=(1, 1)),\n",
    "            torch.nn.BatchNorm2d(self.image_len*4),\n",
    "            torch.nn.LeakyReLU(self.leak_value)\n",
    "        )\n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.image_len*4, self.image_len*8, kernel_size=4, stride=2, bias=self.bias, padding=(1, 1)),\n",
    "            torch.nn.BatchNorm2d(self.image_len*8),\n",
    "            torch.nn.LeakyReLU(self.leak_value)\n",
    "        )\n",
    "        self.layer5 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(self.image_len*8, 1, kernel_size=4, stride=2, bias=self.bias, padding=padd),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x)\n",
    "        out = x.view(-1, 1, self.image_len, self.image_len)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "#         print(out.size())  # torch.Size([1, 1, 1, 1])\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANModel(BaseModel):\n",
    "    def initialize(self, opt):\n",
    "        BaseModel.initialize(self, opt)\n",
    "        # load/define networks\n",
    "        self.encoder2d = Encoder2d()\n",
    "        self.decoder3d = Decoder3d()\n",
    "        self.encoder3d = Encoder3d()\n",
    "        self.decoder2d = Decoder2d()\n",
    "        self.netG_A = nn.Sequential(self.encoder2d, self.decoder3d)\n",
    "        self.netG_B = nn.Sequential(self.encoder3d, self.decoder2d)\n",
    "        self.netD_A = Discriminator3d()\n",
    "        self.netD_B = Discriminator2d()\n",
    "        \n",
    "        # optimizers\n",
    "        self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), \\\n",
    "                                                            self.netG_B.parameters()),\\\n",
    "                                                lr=1E-3, betas=(opt.beta1, 0.999))\n",
    "        self.optimizer_D_A = torch.optim.Adam(self.netD_A.parameters(), lr=1E-3, betas=(opt.beta1, 0.999))\n",
    "        self.optimizer_D_B = torch.optim.Adam(self.netD_B.parameters(), lr=1E-3, betas=(opt.beta1, 0.999))\n",
    "    \n",
    "        \n",
    "        # fake pools to train discrtiminators\n",
    "        self.fake_A_pool = ImagePool(opt.pool_size)\n",
    "        self.fake_B_pool = ImagePool(opt.pool_size)\n",
    "        \n",
    "        # define loss functions\n",
    "        self.criterionGAN = GANLoss()\n",
    "        self.criterionCycle = torch.nn.L1Loss()\n",
    "        self.criterionIdt = torch.nn.L1Loss() # may be needed if done with supervision\n",
    "        \n",
    "    def set_input(self, input_A, input_B):\n",
    "#         AtoB = self.opt.which_direction == 'AtoB'\n",
    "#         input_A = input['A' if AtoB else 'B']\n",
    "#         input_B = input['B' if AtoB else 'A']\n",
    "        self.input_A = input_A\n",
    "        self.input_B = input_B\n",
    "#         self.image_paths = input['A_paths' if AtoB else 'B_paths']\n",
    "\n",
    "    def forward(self):\n",
    "        self.real_A = Variable(self.input_A)\n",
    "        self.real_B = Variable(self.input_B)\n",
    "\n",
    "    def test(self):\n",
    "        real_A = Variable(self.input_A, volatile=True)\n",
    "        fake_B = self.netG_A(real_A)\n",
    "        self.rec_A = self.netG_B(fake_B).data\n",
    "        self.fake_B = fake_B.data\n",
    "\n",
    "        real_B = Variable(self.input_B, volatile=True)\n",
    "        fake_A = self.netG_B(real_B)\n",
    "        self.rec_B = self.netG_A(fake_A).data\n",
    "        self.fake_A = fake_A.data\n",
    "       \n",
    "        \n",
    "    def backward_D_basic(self, netD, real, fake):\n",
    "        # Real\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "        # Fake\n",
    "        pred_fake = netD(fake.detach())\n",
    "        loss_D_fake = self.criterionGAN(pred_fake, False)\n",
    "        # Combined loss\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        # backward\n",
    "        loss_D.backward()\n",
    "        return loss_D\n",
    "\n",
    "    def backward_D_A(self):\n",
    "        fake_B = self.fake_B_pool.query(self.fake_B)\n",
    "        loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
    "        self.loss_D_A = loss_D_A.data[0]\n",
    "\n",
    "    def backward_D_B(self):\n",
    "        fake_A = self.fake_A_pool.query(self.fake_A)\n",
    "        loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
    "        self.loss_D_B = loss_D_B.data[0]\n",
    "\n",
    "    def backward_G(self):\n",
    "        lambda_idt = self.opt.lambda_identity\n",
    "        lambda_A = self.opt.lambda_A\n",
    "        lambda_B = self.opt.lambda_B\n",
    "#         # Identity loss\n",
    "        if lambda_idt > 0:\n",
    "            # G_A should be identity if real_B is fed.\n",
    "            idt_A = self.netG_A(self.real_B)\n",
    "            loss_idt_A = self.criterionIdt(idt_A, self.real_B) * lambda_B * lambda_idt\n",
    "            # G_B should be identity if real_A is fed.\n",
    "            idt_B = self.netG_B(self.real_A)\n",
    "            loss_idt_B = self.criterionIdt(idt_B, self.real_A) * lambda_A * lambda_idt\n",
    "\n",
    "            self.idt_A = idt_A.data\n",
    "            self.idt_B = idt_B.data\n",
    "            self.loss_idt_A = loss_idt_A.data[0]\n",
    "            self.loss_idt_B = loss_idt_B.data[0]\n",
    "        else:\n",
    "            loss_idt_A = 0\n",
    "            loss_idt_B = 0\n",
    "            self.loss_idt_A = 0\n",
    "            self.loss_idt_B = 0\n",
    "\n",
    "        # GAN loss D_A(G_A(A))\n",
    "        fake_B = self.netG_A(self.real_A)\n",
    "        pred_fake = self.netD_A(fake_B)\n",
    "        loss_G_A = self.criterionGAN(pred_fake, True)\n",
    "\n",
    "        # GAN loss D_B(G_B(B))\n",
    "        fake_A = self.netG_B(self.real_B)\n",
    "        pred_fake = self.netD_B(fake_A)\n",
    "        loss_G_B = self.criterionGAN(pred_fake, True)\n",
    "\n",
    "        # Forward cycle loss\n",
    "        rec_A = self.netG_B(fake_B)\n",
    "        loss_cycle_A = self.criterionCycle(rec_A, self.real_A) * lambda_A\n",
    "\n",
    "        # Backward cycle loss\n",
    "        rec_B = self.netG_A(fake_A)\n",
    "        loss_cycle_B = self.criterionCycle(rec_B, self.real_B) * lambda_B\n",
    "        # combined loss\n",
    "        loss_G = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B + loss_idt_A + loss_idt_B\n",
    "        loss_G.backward()\n",
    "\n",
    "        self.fake_B = fake_B.data\n",
    "        self.fake_A = fake_A.data\n",
    "        self.rec_A = rec_A.data\n",
    "        self.rec_B = rec_B.data\n",
    "\n",
    "        self.loss_G_A = loss_G_A.data[0]\n",
    "        self.loss_G_B = loss_G_B.data[0]\n",
    "        self.loss_cycle_A = loss_cycle_A.data[0]\n",
    "        self.loss_cycle_B = loss_cycle_B.data[0]\n",
    "        \n",
    "    def optimize_parameters(self):\n",
    "        # forward\n",
    "        self.forward()\n",
    "        # G_A and G_B\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizer_G.step()\n",
    "        # D_A\n",
    "        self.optimizer_D_A.zero_grad()\n",
    "        self.backward_D_A()\n",
    "        self.optimizer_D_A.step()\n",
    "        # D_B\n",
    "        self.optimizer_D_B.zero_grad()\n",
    "        self.backward_D_B()\n",
    "        self.optimizer_D_B.step()\n",
    "        \n",
    "    def get_current_errors(self):\n",
    "        ret_errors = OrderedDict([('D_A', self.loss_D_A), ('G_A', self.loss_G_A), ('Cyc_A', self.loss_cycle_A),\n",
    "                                  ('D_B', self.loss_D_B), ('G_B', self.loss_G_B), ('Cyc_B', self.loss_cycle_B)])\n",
    "        if self.opt.lambda_identity > 0.0:\n",
    "            ret_errors['idt_A'] = self.loss_idt_A\n",
    "            ret_errors['idt_B'] = self.loss_idt_B\n",
    "        return ret_errors\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        real_A = util.tensor2im(self.input_A)\n",
    "        fake_B = util.tensor2im(self.fake_B)\n",
    "        rec_A = util.tensor2im(self.rec_A)\n",
    "        real_B = util.tensor2im(self.input_B)\n",
    "        fake_A = util.tensor2im(self.fake_A)\n",
    "        rec_B = util.tensor2im(self.rec_B)\n",
    "        ret_visuals = OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('rec_A', rec_A),\n",
    "                                   ('real_B', real_B), ('fake_A', fake_A), ('rec_B', rec_B)])\n",
    "        if self.opt.isTrain and self.opt.lambda_identity > 0.0:\n",
    "            ret_visuals['idt_A'] = util.tensor2im(self.idt_A)\n",
    "            ret_visuals['idt_B'] = util.tensor2im(self.idt_B)\n",
    "        return ret_visuals\n",
    "\n",
    "    def save(self, label):\n",
    "        self.save_network(self.netG_A, 'G_A', label)\n",
    "        self.save_network(self.netD_A, 'D_A', label)\n",
    "        self.save_network(self.netG_B, 'G_B', label)\n",
    "        self.save_network(self.netD_B, 'D_B', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "bsize = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_data = [np.load('voxels.npy'), np.load('padded_gray_images.npy')]\n",
    "for _ in range(len(train_data)):\n",
    "    train_data[_] =torch.from_numpy(train_data[_]).type(torch.FloatTensor)\n",
    "    if cuda:\n",
    "        train_data[_] = train_data[_].cuda()\n",
    "train_data = [(train_data[0][i], train_data[1][i]) for i in range(len(train_data[0]))] \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=bsize, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CycleGANModel()\n",
    "model.initialize(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-1de58f1ba5da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdata2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata3d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-6a007ffc921c>\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# G_A and G_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_G\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# D_A\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-138-6a007ffc921c>\u001b[0m in \u001b[0;36mbackward_G\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# combined loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mloss_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_G_A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_G_B\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_cycle_A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_cycle_B\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_idt_A\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_idt_B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mloss_G\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake_B\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    iter_data_time = time.time()\n",
    "    epoch_iter = 0\n",
    "\n",
    "    for batch_idx, (data3d, data2d) in enumerate(train_loader):\n",
    "        data3d = data3d.unsqueeze(1)\n",
    "        data2d = data2d.unsqueeze(1)\n",
    "        model.set_input(data2d, data3d)\n",
    "        model.optimize_parameters()\n",
    "        \n",
    "    if batch_idx % 10 == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch+1, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader),\n",
    "            model.get_current_errors()))\n",
    "\n",
    "    print('saving the model at the end of epoch %d' %\n",
    "          (epoch))\n",
    "    model.save('latest')\n",
    "    model.save(epoch)\n",
    "\n",
    "    print('End of epoch %d\\t Time Taken: %d sec' %\n",
    "          (epoch, time.time() - epoch_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 32, 32, 32])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
